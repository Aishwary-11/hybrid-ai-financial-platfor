"""
AI Orchestrator - Central Coordination System
BlackRock Aladdin-inspired hybrid AI architecture with foundation and specialized models
"""

import asyncio
import logging
from typing import Dict, List, Optional, Any, Union
from datetime import datetime
from dataclasses import dataclass
from enum import Enum
import json
from abc import ABC, abstractmethod

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class QueryType(Enum):
    """Types of investment queries"""
    EARNINGS_ANALYSIS = "earnings_analysis"
    THEMATIC_IDENTIFICATION = "thematic_identification"
    SENTIMENT_ANALYSIS = "sentiment_analysis"
    RISK_ASSESSMENT = "risk_assessment"
    PORTFOLIO_OPTIMIZATION = "portfolio_optimization"
    MARKET_FORECAST = "market_forecast"
    GENERAL_ANALYSIS = "general_analysis"


class ModelType(Enum):
    """Types of AI models in the system"""
    FOUNDATION = "foundation"  # GPT-4, Gemini, Claude
    SPECIALIZED = "specialized"  # Custom fine-tuned models
    ENSEMBLE = "ensemble"  # Combination of multiple models


class RoutingStrategy(Enum):
    """Model routing strategies"""
    CONFIDENCE_BASED = "confidence_based"
    SPECIALIZATION_FIRST = "specialization_first"
    PARALLEL_ENSEMBLE = "parallel_ensemble"
    FOUNDATION_FALLBACK = "foundation_fallback"


@dataclass
class InvestmentQuery:
    """Investment query data structure"""
    query_text: str
    query_type: QueryType
    symbols: List[str]
    time_horizon: str
    risk_tolerance: str
    user_context: Dict[str, Any]
    timestamp: datetime
    metadata: Dict[str, Any] = None


@dataclass
class ModelResponse:
    """Response from individual AI model"""
    model_id: str
    model_type: ModelType
    prediction: Any
    confidence: float
    explanation: str
    processing_time: float
    metadata: Dict[str, Any]
    timestamp: datetime


@dataclass
class OrchestrationResult:
    """Final orchestrated result"""
    query_id: str
    synthesized_response: Any
    confidence: float
    model_responses: List[ModelResponse]
    routing_strategy: RoutingStrategy
    human_review_required: bool
    processing_time: float
    timestamp: datetime

class AIModel(ABC):
    """Abstract base class for all AI models"""
    
    def __init__(self, model_id: str, model_type: ModelType):
        self.model_id = model_id
        self.model_type = model_type
        self.is_available = True
        self.performance_metrics = {}
        
    @abstractmethod
    async def predict(self, query: InvestmentQuery) -> ModelResponse:
        """Generate prediction for investment query"""
        pass
    
    @abstractmethod
    def get_capabilities(self) -> List[QueryType]:
        """Return list of query types this model can handle"""
        pass
    
    @abstractmethod
    async def health_check(self) -> bool:
        """Check if model is healthy and available"""
        pass


class FoundationModel(AIModel):
    """Foundation model (GPT-4, Gemini, Claude) integration"""
    
    def __init__(self, model_id: str, api_endpoint: str, api_key: str):
        super().__init__(model_id, ModelType.FOUNDATION)
        self.api_endpoint = api_endpoint
        self.api_key = api_key
        
    async def predict(self, query: InvestmentQuery) -> ModelResponse:
        """Generate prediction using foundation model"""
        start_time = datetime.now()
        
        try:
            # Simulate foundation model API call
            await asyncio.sleep(0.5)  # Simulate API latency
            
            # Generate response based on query type
            response = await self._generate_foundation_response(query)
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return ModelResponse(
                model_id=self.model_id,
                model_type=self.model_type,
                prediction=response,
                confidence=0.75,  # Foundation models have good general confidence
                explanation=f"Analysis generated by {self.model_id} foundation model",
                processing_time=processing_time,
                metadata={"api_endpoint": self.api_endpoint},
                timestamp=datetime.now()
            )
            
        except Exception as e:
            logger.error(f"Foundation model {self.model_id} prediction failed: {e}")
            raise
    
    async def _generate_foundation_response(self, query: InvestmentQuery) -> Dict[str, Any]:
        """Generate response using foundation model capabilities"""
        
        if query.query_type == QueryType.GENERAL_ANALYSIS:
            return {
                "analysis": f"General market analysis for {', '.join(query.symbols)}",
                "recommendation": "Based on broad market knowledge and cross-domain reasoning",
                "key_factors": ["Market sentiment", "Economic indicators", "Sector trends"],
                "confidence_note": "Foundation model provides comprehensive general analysis"
            }
        elif query.query_type == QueryType.MARKET_FORECAST:
            return {
                "forecast": f"Market forecast for {query.time_horizon} horizon",
                "trend_direction": "neutral_to_positive",
                "key_drivers": ["Economic policy", "Corporate earnings", "Global events"],
                "risk_factors": ["Volatility", "Geopolitical events", "Interest rates"]
            }
        else:
            return {
                "analysis": f"Foundation model analysis for {query.query_type.value}",
                "recommendation": "Defer to specialized models for domain-specific accuracy",
                "note": "Foundation model provides general reasoning support"
            }
    
    def get_capabilities(self) -> List[QueryType]:
        """Foundation models can handle all query types with general reasoning"""
        return list(QueryType)
    
    async def health_check(self) -> bool:
        """Check foundation model API health"""
        try:
            # Simulate API health check
            await asyncio.sleep(0.1)
            return True
        except:
            return False


class SpecializedModel(AIModel):
    """Specialized fine-tuned model for specific financial tasks"""
    
    def __init__(self, model_id: str, specialization: QueryType, model_path: str):
        super().__init__(model_id, ModelType.SPECIALIZED)
        self.specialization = specialization
        self.model_path = model_path
        self.training_data_size = 0
        self.accuracy_metrics = {}
        
    async def predict(self, query: InvestmentQuery) -> ModelResponse:
        """Generate prediction using specialized model"""
        start_time = datetime.now()
        
        try:
            # Verify this model can handle the query type
            if query.query_type != self.specialization:
                raise ValueError(f"Model {self.model_id} cannot handle {query.query_type}")
            
            # Generate specialized response
            response = await self._generate_specialized_response(query)
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return ModelResponse(
                model_id=self.model_id,
                model_type=self.model_type,
                prediction=response,
                confidence=0.90,  # Specialized models have higher domain confidence
                explanation=f"Specialized analysis by {self.model_id} trained on domain-specific data",
                processing_time=processing_time,
                metadata={
                    "specialization": self.specialization.value,
                    "training_data_size": self.training_data_size
                },
                timestamp=datetime.now()
            )
            
        except Exception as e:
            logger.error(f"Specialized model {self.model_id} prediction failed: {e}")
            raise
    
    async def _generate_specialized_response(self, query: InvestmentQuery) -> Dict[str, Any]:
        """Generate response using specialized model"""
        
        if self.specialization == QueryType.EARNINGS_ANALYSIS:
            return {
                "investment_signal": "bullish",
                "signal_strength": 0.78,
                "key_themes": ["revenue_growth", "margin_expansion", "digital_transformation"],
                "risk_factors": ["competition", "regulatory_changes"],
                "price_target_adjustment": "increase_5_percent",
                "earnings_sentiment": 0.72,
                "analyst_consensus": "positive"
            }
        elif self.specialization == QueryType.THEMATIC_IDENTIFICATION:
            return {
                "top_themes": [
                    {"name": "artificial_intelligence", "strength": 0.85, "sources": ["news", "patents"]},
                    {"name": "clean_energy", "strength": 0.78, "sources": ["regulatory", "market"]},
                    {"name": "cybersecurity", "strength": 0.71, "sources": ["news", "market"]}
                ],
                "investment_vehicles": {
                    "artificial_intelligence": ["ARKQ", "BOTZ", "AI stocks"],
                    "clean_energy": ["ICLN", "PBW", "Solar companies"]
                },
                "time_horizons": {
                    "artificial_intelligence": "2-5 years",
                    "clean_energy": "3-7 years"
                }
            }
        elif self.specialization == QueryType.SENTIMENT_ANALYSIS:
            return {
                "overall_sentiment": 0.65,
                "sentiment_trend": "improving",
                "news_sentiment": 0.72,
                "social_sentiment": 0.58,
                "analyst_sentiment": 0.68,
                "sentiment_drivers": ["earnings_beats", "positive_guidance", "sector_rotation"]
            }
        else:
            return {
                "analysis": f"Specialized analysis for {self.specialization.value}",
                "confidence": 0.90,
                "note": "High-accuracy domain-specific analysis"
            }
    
    def get_capabilities(self) -> List[QueryType]:
        """Specialized models handle only their specific domain"""
        return [self.specialization]
    
    async def health_check(self) -> bool:
        """Check specialized model health"""
        try:
            # Simulate model health check
            await asyncio.sleep(0.05)
            return True
        except:
            return False


class AIOrchestrator:
    """Central AI orchestration system for hybrid model architecture"""
    
    def __init__(self):
        self.foundation_models: Dict[str, FoundationModel] = {}
        self.specialized_models: Dict[str, SpecializedModel] = {}
        self.model_registry: Dict[str, AIModel] = {}
        self.routing_strategies = {
            RoutingStrategy.CONFIDENCE_BASED: self._route_by_confidence,
            RoutingStrategy.SPECIALIZATION_FIRST: self._route_specialization_first,
            RoutingStrategy.PARALLEL_ENSEMBLE: self._route_parallel_ensemble,
            RoutingStrategy.FOUNDATION_FALLBACK: self._route_with_fallback
        }
        self.performance_metrics = {}
        
    def register_foundation_model(self, model: FoundationModel):
        """Register a foundation model"""
        self.foundation_models[model.model_id] = model
        self.model_registry[model.model_id] = model
        logger.info(f"Registered foundation model: {model.model_id}")
    
    def register_specialized_model(self, model: SpecializedModel):
        """Register a specialized model"""
        self.specialized_models[model.model_id] = model
        self.model_registry[model.model_id] = model
        logger.info(f"Registered specialized model: {model.model_id} for {model.specialization.value}")
    
    async def process_request(
        self,
        query: InvestmentQuery,
        routing_strategy: RoutingStrategy = RoutingStrategy.SPECIALIZATION_FIRST
    ) -> OrchestrationResult:
        """Main entry point for processing investment queries"""
        
        start_time = datetime.now()
        query_id = f"query_{int(start_time.timestamp())}"
        
        logger.info(f"Processing query {query_id}: {query.query_type.value}")
        
        try:
            # Route query to appropriate models
            model_responses = await self._route_query(query, routing_strategy)
            
            # Synthesize responses from multiple models
            synthesized_response = await self._synthesize_responses(model_responses, query)
            
            # Determine if human review is required
            human_review_required = self._requires_human_review(model_responses, synthesized_response)
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            result = OrchestrationResult(
                query_id=query_id,
                synthesized_response=synthesized_response,
                confidence=self._calculate_overall_confidence(model_responses),
                model_responses=model_responses,
                routing_strategy=routing_strategy,
                human_review_required=human_review_required,
                processing_time=processing_time,
                timestamp=datetime.now()
            )
            
            # Update performance metrics
            await self._update_performance_metrics(result)
            
            logger.info(f"Query {query_id} processed in {processing_time:.2f}s")
            return result
            
        except Exception as e:
            logger.error(f"Query processing failed for {query_id}: {e}")
            raise
    
    async def _route_query(
        self,
        query: InvestmentQuery,
        strategy: RoutingStrategy
    ) -> List[ModelResponse]:
        """Route query to appropriate models based on strategy"""
        
        routing_func = self.routing_strategies.get(strategy, self._route_specialization_first)
        return await routing_func(query)
    
    async def _route_specialization_first(self, query: InvestmentQuery) -> List[ModelResponse]:
        """Route to specialized models first, fallback to foundation models"""
        
        responses = []
        
        # Try specialized models first
        for model in self.specialized_models.values():
            if query.query_type in model.get_capabilities() and await model.health_check():
                try:
                    response = await model.predict(query)
                    responses.append(response)
                    logger.info(f"Specialized model {model.model_id} responded with confidence {response.confidence}")
                except Exception as e:
                    logger.warning(f"Specialized model {model.model_id} failed: {e}")
        
        # If no specialized model succeeded or confidence is low, use foundation model
        if not responses or max(r.confidence for r in responses) < 0.7:
            for model in self.foundation_models.values():
                if await model.health_check():
                    try:
                        response = await model.predict(query)
                        responses.append(response)
                        logger.info(f"Foundation model {model.model_id} provided fallback response")
                        break
                    except Exception as e:
                        logger.warning(f"Foundation model {model.model_id} failed: {e}")
        
        return responses
    
    async def _route_parallel_ensemble(self, query: InvestmentQuery) -> List[ModelResponse]:
        """Route to multiple models in parallel for ensemble prediction"""
        
        tasks = []
        
        # Add specialized models that can handle the query
        for model in self.specialized_models.values():
            if query.query_type in model.get_capabilities():
                tasks.append(self._safe_predict(model, query))
        
        # Add one foundation model for general reasoning
        if self.foundation_models:
            foundation_model = next(iter(self.foundation_models.values()))
            tasks.append(self._safe_predict(foundation_model, query))
        
        # Execute all predictions in parallel
        responses = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Filter out exceptions and return valid responses
        valid_responses = [r for r in responses if isinstance(r, ModelResponse)]
        
        logger.info(f"Parallel ensemble generated {len(valid_responses)} responses")
        return valid_responses
    
    async def _route_by_confidence(self, query: InvestmentQuery) -> List[ModelResponse]:
        """Route based on historical model confidence for query type"""
        
        # Get models sorted by historical performance for this query type
        suitable_models = []
        
        for model in self.model_registry.values():
            if query.query_type in model.get_capabilities():
                historical_confidence = self.performance_metrics.get(
                    f"{model.model_id}_{query.query_type.value}", 0.5
                )
                suitable_models.append((model, historical_confidence))
        
        # Sort by confidence and try best model first
        suitable_models.sort(key=lambda x: x[1], reverse=True)
        
        for model, _ in suitable_models:
            if await model.health_check():
                try:
                    response = await model.predict(query)
                    return [response]
                except Exception as e:
                    logger.warning(f"Model {model.model_id} failed: {e}")
                    continue
        
        return []
    
    async def _route_with_fallback(self, query: InvestmentQuery) -> List[ModelResponse]:
        """Route with systematic fallback strategy"""
        
        # Try specialized models first
        responses = await self._route_specialization_first(query)
        
        # If no good responses, try all available models
        if not responses or max(r.confidence for r in responses) < 0.6:
            logger.info("Primary routing failed, trying all available models")
            
            for model in self.model_registry.values():
                if query.query_type in model.get_capabilities() and await model.health_check():
                    try:
                        response = await model.predict(query)
                        responses.append(response)
                    except Exception as e:
                        logger.warning(f"Fallback model {model.model_id} failed: {e}")
        
        return responses
    
    async def _safe_predict(self, model: AIModel, query: InvestmentQuery) -> Optional[ModelResponse]:
        """Safely execute model prediction with error handling"""
        try:
            if await model.health_check():
                return await model.predict(query)
        except Exception as e:
            logger.warning(f"Model {model.model_id} prediction failed: {e}")
        return None
    
    async def _synthesize_responses(
        self,
        responses: List[ModelResponse],
        query: InvestmentQuery
    ) -> Dict[str, Any]:
        """Synthesize multiple model responses into coherent result"""
        
        if not responses:
            return {"error": "No model responses available", "query_type": query.query_type.value}
        
        if len(responses) == 1:
            return responses[0].prediction
        
        # Multi-model synthesis
        synthesis = {
            "query_type": query.query_type.value,
            "model_count": len(responses),
            "synthesis_method": "weighted_average",
            "individual_responses": {}
        }
        
        # Collect individual responses
        for response in responses:
            synthesis["individual_responses"][response.model_id] = {
                "prediction": response.prediction,
                "confidence": response.confidence,
                "model_type": response.model_type.value
            }
        
        # Weighted synthesis based on confidence and model type
        specialized_responses = [r for r in responses if r.model_type == ModelType.SPECIALIZED]
        foundation_responses = [r for r in responses if r.model_type == ModelType.FOUNDATION]
        
        if specialized_responses:
            # Prioritize specialized model responses
            best_specialized = max(specialized_responses, key=lambda r: r.confidence)
            synthesis["primary_prediction"] = best_specialized.prediction
            synthesis["primary_model"] = best_specialized.model_id
            synthesis["confidence"] = best_specialized.confidence
        elif foundation_responses:
            # Use foundation model as fallback
            best_foundation = max(foundation_responses, key=lambda r: r.confidence)
            synthesis["primary_prediction"] = best_foundation.prediction
            synthesis["primary_model"] = best_foundation.model_id
            synthesis["confidence"] = best_foundation.confidence
        
        return synthesis
    
    def _calculate_overall_confidence(self, responses: List[ModelResponse]) -> float:
        """Calculate overall confidence from multiple model responses"""
        if not responses:
            return 0.0
        
        # Weight specialized models higher
        total_weight = 0
        weighted_confidence = 0
        
        for response in responses:
            weight = 1.5 if response.model_type == ModelType.SPECIALIZED else 1.0
            weighted_confidence += response.confidence * weight
            total_weight += weight
        
        return weighted_confidence / total_weight if total_weight > 0 else 0.0
    
    def _requires_human_review(
        self,
        responses: List[ModelResponse],
        synthesized_response: Dict[str, Any]
    ) -> bool:
        """Determine if human review is required"""
        
        if not responses:
            return True
        
        overall_confidence = self._calculate_overall_confidence(responses)
        
        # Require human review for low confidence
        if overall_confidence < 0.7:
            return True
        
        # Require review for conflicting model responses
        if len(responses) > 1:
            confidence_variance = np.var([r.confidence for r in responses])
            if confidence_variance > 0.1:  # High variance in confidence
                return True
        
        # Require review for high-stakes queries
        high_stakes_queries = [QueryType.RISK_ASSESSMENT, QueryType.PORTFOLIO_OPTIMIZATION]
        if any(r.metadata.get("query_type") in high_stakes_queries for r in responses):
            return True
        
        return False
    
    async def _update_performance_metrics(self, result: OrchestrationResult):
        """Update performance metrics for continuous improvement"""
        
        for response in result.model_responses:
            metric_key = f"{response.model_id}_{result.query_id.split('_')[0]}"
            
            if metric_key not in self.performance_metrics:
                self.performance_metrics[metric_key] = []
            
            self.performance_metrics[metric_key].append({
                "confidence": response.confidence,
                "processing_time": response.processing_time,
                "timestamp": response.timestamp.isoformat()
            })
    
    async def get_system_status(self) -> Dict[str, Any]:
        """Get comprehensive system status"""
        
        status = {
            "foundation_models": {},
            "specialized_models": {},
            "system_health": "healthy",
            "total_models": len(self.model_registry),
            "performance_metrics": self.performance_metrics,
            "timestamp": datetime.now().isoformat()
        }
        
        # Check foundation model health
        for model_id, model in self.foundation_models.items():
            health = await model.health_check()
            status["foundation_models"][model_id] = {
                "healthy": health,
                "capabilities": [c.value for c in model.get_capabilities()]
            }
        
        # Check specialized model health
        for model_id, model in self.specialized_models.items():
            health = await model.health_check()
            status["specialized_models"][model_id] = {
                "healthy": health,
                "specialization": model.specialization.value,
                "training_data_size": model.training_data_size
            }
        
        # Overall system health
        all_healthy = all(
            await model.health_check() for model in self.model_registry.values()
        )
        status["system_health"] = "healthy" if all_healthy else "degraded"
        
        return status